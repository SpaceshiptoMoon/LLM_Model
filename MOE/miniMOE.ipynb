{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 完全从零写一个 MOE 大模型（LLM）\n",
    "Build a miniMoE-LLM from scratch\n",
    "从零开始构建 MoE 模型，从基础讲起，共讲解三个版本\n",
    "1. 基础版本，理解MOE\n",
    "2. SparseMoE，了解大模型怎么训练 MOE LLM\n",
    "3. ShareExpert SparseMoe，了解 deepseek 训练 MOE 模型算法\n"
   ],
   "id": "8bd80df4ccda47da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 版本1： 基础版MOE\n",
   "id": "fce9d12b508dd2af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T07:28:57.277683Z",
     "start_time": "2025-05-16T07:28:46.589101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "id": "9b93d8bddf4bdb4c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T07:28:57.341662Z",
     "start_time": "2025-05-16T07:28:57.324660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BasicExpert(nn.Module):\n",
    "    # 一个 Expert 可以是一个最简单的， linear 层即可\n",
    "    # 也可以是 MLP 层\n",
    "    # 也可以是 更复杂的 MLP 层（active function 设置为 swiglu）\n",
    "    def __init__(self, feature_in, feature_out):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(feature_in, feature_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n"
   ],
   "id": "3a6c29e2e9ceb558",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T07:28:57.403569Z",
     "start_time": "2025-05-16T07:28:57.376639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BasicMOE(nn.Module):\n",
    "    def __init__(self, feature_in, feature_out, expert_number):\n",
    "        super().__init__()\n",
    "        self.experts = nn.ModuleList(\n",
    "            [\n",
    "                BasicExpert(feature_in, feature_out) for _ in range(expert_number)\n",
    "            ]\n",
    "        )\n",
    "        # gate 就是选择一个 expert\n",
    "        self.gate = nn.Linear(feature_in, expert_number)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 的 shape 是 (batch, feature_in)\n",
    "        expert_weight = self.gate(x) # shape 是 (batch, expert_number)\n",
    "        expert_out_list = [\n",
    "            expert(x).unsqueeze(1) for expert in self.experts\n",
    "                           ] # 里面每一个元素的 shape 是： (batch, 1, feature_out)\n",
    "        # concat 起来 (batch, expert_number, feature_out)\n",
    "        expert_output = torch.concat(expert_out_list, dim = 1)\n",
    "\n",
    "        # print(expert_output.size())\n",
    "\n",
    "        expert_weight = expert_weight.unsqueeze(1) # (batch, 1, expert_number)\n",
    "        expert_weight = F.softmax(expert_weight, dim = -1)\n",
    "\n",
    "        # expert_weight * expert_out_list\n",
    "        output = expert_weight @ expert_output # (batch, 1, feature_out)\n",
    "\n",
    "        return output.squeeze(1)"
   ],
   "id": "f2339227bf19441",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T07:28:57.634960Z",
     "start_time": "2025-05-16T07:28:57.437566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_basic_moe():\n",
    "    x = torch.rand(2, 4)\n",
    "\n",
    "    basic_moe = BasicMOE(4, 3, 2)\n",
    "    out = basic_moe(x)\n",
    "    print(out)\n",
    "    print(out.shape)\n",
    "\n",
    "test_basic_moe()"
   ],
   "id": "2eece9c001d2d79f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7145,  0.0609, -0.8199],\n",
      "        [-0.6657, -0.3102, -0.5012]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 版本2： SparseMoe",
   "id": "1beb3238fa36e1f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T07:28:59.264515Z",
     "start_time": "2025-05-16T07:28:59.174179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MOERouter(nn.Module):\n",
    "    # 选择专家模型, 返回选择的专家模型索引和专家模型的gate\n",
    "    def __init__(self, hidden_dim, expert_number, top_k):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        hidden_dim :\n",
    "        expert_number : 专家的个数\n",
    "        top_K : 每次通过选择激活几个专家\n",
    "        \"\"\"\n",
    "        self.gate = nn.Linear(hidden_dim, expert_number)\n",
    "        self.expert_number = expert_number\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # 计算router_logits\n",
    "        router_logits = self.gate(hidden_states) # (b * s, expert_number)\n",
    "\n",
    "        # 计算专家经过的softmax之后的概率\n",
    "        routing_probs = F.softmax(router_logits, dim=-1, dtype=torch.float) # (b * s, expert_number)\n",
    "\n",
    "        # 计算前top_k专家的输出\n",
    "        router_weights, selected_experts_idex = torch.topk(\n",
    "            routing_probs, self.top_k, dim=-1\n",
    "        )\n",
    "        # (b * s, top_k)  torch.topk()在-1维选择topk个元素, return routing_probs选择的元素和对应的索引\n",
    "        \"\"\"\n",
    "        Example::\n",
    "\n",
    "        >>> x = torch.arange(1., 6.)\n",
    "        >>> x\n",
    "        tensor([ 1.,  2.,  3.,  4.,  5.])\n",
    "        >>> torch.topk(x, 3)\n",
    "        torch.return_types.topk(values=tensor([5., 4., 3.]), indices=tensor([4, 3, 2]))\n",
    "        \"\"\"\n",
    "\n",
    "        # 专家权重归一化\n",
    "        routing_weights = router_weights / router_weights.sum(dim=-1, keepdim=True) # (b * s, top_k)\n",
    "        router_weights = routing_weights.to(hidden_states.dtype) # (b * s, top_k)\n",
    "\n",
    "        # 生成专家掩码\n",
    "        expert_mask = F.one_hot(\n",
    "            selected_experts_idex,\n",
    "            num_classes=self.expert_number\n",
    "        ) # (b * s, top_k, expert_number)\n",
    "        # expert_mask 为专家对应的索引one_hot形式\n",
    "        expert_mask = expert_mask.permute(2, 1, 0) # (expert_number, top_k, b * s)\n",
    "        \"\"\"\n",
    "        Examples:\n",
    "        >>> F.one_hot(torch.arange(0, 5) % 3)\n",
    "        tensor([[1, 0, 0],\n",
    "                [0, 1, 0],\n",
    "                [0, 0, 1],\n",
    "                [1, 0, 0],\n",
    "                [0, 1, 0]])\n",
    "        >>> F.one_hot(torch.arange(0, 5) % 3, num_classes=5)\n",
    "        tensor([[1, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0],\n",
    "                [1, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0]])\n",
    "        >>> F.one_hot(torch.arange(0, 6).view(3,2) % 3) => (3, 2, 3)\n",
    "        tensor([[[1, 0, 0],\n",
    "                 [0, 1, 0]],\n",
    "                [[0, 0, 1],\n",
    "                 [1, 0, 0]],\n",
    "                [[0, 1, 0],\n",
    "                 [0, 0, 1]]])\n",
    "        \"\"\"\n",
    "        return router_logits, router_weights, selected_experts_idex, expert_mask\n",
    "\n",
    "\n",
    "class MOEconfig:\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dim, #\n",
    "            expert_number,\n",
    "            top_k,\n",
    "            shared_experts_number = 2\n",
    "            ):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.expert_number = expert_number\n",
    "        self.top_k = top_k\n",
    "        self.shared_experts_number = shared_experts_number\n",
    "\n",
    "class SparseMOE(nn.Module):\n",
    "    # 稀疏 MOE 模型，这里每一个 token 都会过 topk 个专家，得到对应token 的 hidden_embeddings\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = config.hidden_dim\n",
    "        self.expert_number = config.expert_number\n",
    "        self.top_k = config.top_k\n",
    "\n",
    "        self.experts = nn.ModuleList(\n",
    "            [\n",
    "                BasicExpert(self.hidden_dim, self.hidden_dim) for _ in range(self.expert_number)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.router = MOERouter(self.hidden_dim, self.expert_number, self.top_k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape is (b, s, hidden_dim)\n",
    "        batch_size, seq_len, hidden_dim = x.size()\n",
    "\n",
    "        # 合并前两个维度, 因为不是 Sample 维度了, 而是 token 维度\n",
    "        hidden_states = x.view(-1, hidden_dim)  # (b * s, hidden_dim)\n",
    "\n",
    "        router_logits, router_weights, selected_experts_indices, expert_mask = self.router(hidden_states)\n",
    "        # router_weights (b * s, top_k)\n",
    "        # 其中 selected_experts_indices shape 是 (b * s, top_k)\n",
    "        # 其中 expert_mask shape 是 (expert_number, top_k, b * s)\n",
    "\n",
    "        final_hidden_states = torch.zeros(\n",
    "            (batch_size * seq_len, hidden_dim),\n",
    "            dtype = hidden_states.dtype,\n",
    "            device = hidden_states.device\n",
    "        )\n",
    "\n",
    "        for expert_idx in range(self.expert_number):\n",
    "            expert_layer = self.experts[expert_idx]\n",
    "\n",
    "            # expert_mask[expert_idx] shape 是 (top_k, b * s)\n",
    "            idx, top_x = torch.where(expert_mask[expert_idx])\n",
    "            # torch.where返回的idx为行索引 ,top_k为列索引\n",
    "            # idx 的值是表示这个 token 是作为当前专家第idx专家\n",
    "\n",
    "            # hidden_states 的 shape 是 (b * s, hidden_dim)\n",
    "            # 需要取到 top_x 对应的 hidden_states\n",
    "            current_states = hidden_states.unsqueeze(\n",
    "                0\n",
    "            )[:, top_x, :].reshape(-1, hidden_dim) # (selected_token_number, hidden_dim）\n",
    "\n",
    "            # router_weight 的 shape 是 (b * s, top_k)\n",
    "            current_hidden_states = expert_layer(\n",
    "                current_states,\n",
    "            ) * router_weights[top_x, idx].unsqueeze(-1) # (selected_token_number, 1)\n",
    "\n",
    "            # 把当前专家的输出加到 final_hidden_states 中\n",
    "            # 方式1 的写法性能更好，并且方式1容易出现\n",
    "            final_hidden_states.index_add_(0, top_x, current_hidden_states)\n",
    "            # 方式2\n",
    "            final_hidden_states[top_x] += current_hidden_states.to(hidden_states.dtype)\n",
    "            # 方式1 的写法性能更差, 并且方式1容易出现错误, += 操作在处理重复索引时需要多次读写内存, 可能会导致竞争条件\n",
    "\n",
    "        # 把 final_hidden_states 还原到原来的 shape\n",
    "        final_hidden_states = final_hidden_states.reshape(batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        return final_hidden_states, router_logits # shape 是 (b * s, expert_number)\n",
    "\n"
   ],
   "id": "46af5c6463d80fe2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T07:37:29.841778Z",
     "start_time": "2025-05-16T07:37:29.806784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_token_level_moe():\n",
    "    x = torch.rand(2, 4, 16)\n",
    "    config = MOEconfig(16, 2, 2)  # hidden_dim, expert_number, top_k,\n",
    "    token_level_moe = SparseMOE(config)\n",
    "    out = token_level_moe(x)\n",
    "    print(out[0].shape, out[1].shape)\n",
    "\n",
    "\n",
    "\n",
    "test_token_level_moe()"
   ],
   "id": "926e7a83bdf81363",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 16]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 版本3：ShareExpert SparseMoE （deepseek 版本）",
   "id": "72bf6a47655985e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:35:44.471561Z",
     "start_time": "2025-05-16T10:35:44.339217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ShareExpertMOE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.moe_model = SparseMOE(config)\n",
    "        self.share_experts = nn.ModuleList(\n",
    "            [\n",
    "                BasicExpert(\n",
    "                    config.hidden_dim, config.hidden_dim\n",
    "                ) for _ in range(config.shared_experts_number)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shape of X  is (b, s, hidden_dim)\n",
    "\n",
    "        # 1. 首先过router模型\n",
    "        sparse_moe_out, router_logits = self.moe_model(x)\n",
    "        # 1. 再过share模型\n",
    "        share_experts_out = [expert(x) for expert in self.share_experts] # (b, s, hidden_dim)\n",
    "\n",
    "        share_experts_out = torch.stack(\n",
    "           share_experts_out, dim=0\n",
    "        ).sum(dim=0)\n",
    "\n",
    "        # 把 sparse_moe_out 和 shared_experts_out 加起来\n",
    "        return sparse_moe_out + share_experts_out, router_logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_share_expert_moe():\n",
    "    x = torch.rand(2, 4, 16)\n",
    "    config = MOEconfig(16, 2, 2)\n",
    "    share_expert_moe = ShareExpertMOE(config)\n",
    "    out = share_expert_moe(x)\n",
    "    print(out[0].shape, out[1].shape)\n",
    "\n",
    "test_share_expert_moe()"
   ],
   "id": "59833985a6d18306",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 16]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:21:19.476307Z",
     "start_time": "2025-05-16T08:21:18.060136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 测试， loss 部分为 deepseek 生成；\n",
    "\n",
    "def switch_load_balancing_loss(router_logits: torch.Tensor, num_experts: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    计算 Switch Transformers 的负载均衡损失\n",
    "\n",
    "    Args:\n",
    "        router_logits: shape [batch_size * sequence_length, num_experts]\n",
    "        num_experts: 专家数量\n",
    "\n",
    "    Returns:\n",
    "        total_loss: 总损失 = auxiliary_loss + z_loss\n",
    "    \"\"\"\n",
    "    # 计算路由概率\n",
    "    router_probs = torch.softmax(router_logits, dim=-1)  # [b*s, num_experts]\n",
    "\n",
    "    # 获取每个token的最优专家\n",
    "    _, selected_experts = torch.topk(router_probs, k=2, dim=-1)  # [b*s]\n",
    "\n",
    "    # 创建one-hot矩阵表示选中的专家\n",
    "    mask = torch.nn.functional.one_hot(selected_experts, num_experts).float()  # [b*s, num_experts]\n",
    "\n",
    "    # 计算每个专家的期望负载 (理想情况下应该是 1/num_experts)\n",
    "    expected_load = torch.ones_like(router_probs) / num_experts\n",
    "\n",
    "    # 计算实际负载 (每个专家处理的token数量除以总token数量)\n",
    "    # 在batch维度上计算平均值\n",
    "    actual_load = mask.mean(dim=0)  # [num_experts]\n",
    "\n",
    "    # 计算auxiliary loss\n",
    "    # 这会惩罚负载分布与期望负载的差异\n",
    "    aux_loss = torch.sum(actual_load * router_probs.mean(dim=0)) * num_experts\n",
    "\n",
    "    # 计算z_loss (可选)\n",
    "    # 这会惩罚过大的路由logits\n",
    "    z_loss = torch.mean(torch.square(router_logits))\n",
    "    z_loss_weight = 0.001  # 可调整的超参数\n",
    "\n",
    "    # 总损失\n",
    "    total_loss = aux_loss + z_loss * z_loss_weight\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def test_moe_training():\n",
    "    # Create a simple dataset\n",
    "    batch_size = 32\n",
    "    seq_len = 16\n",
    "    hidden_dim = 32\n",
    "    num_batches = 100\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    config = MOEconfig(hidden_dim=hidden_dim,\n",
    "                      expert_number=4,\n",
    "                      top_k=2,\n",
    "                      shared_experts_number=2)\n",
    "    model = ShareExpertMOE(config)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for batch in range(num_batches):\n",
    "        # Generate random input data\n",
    "        x = torch.randn(batch_size, seq_len, hidden_dim)\n",
    "        target = torch.randn(batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        # Forward pass\n",
    "        output, router_logits = model(x)\n",
    "\n",
    "        # Compute losses\n",
    "        # MSE loss for prediction\n",
    "        mse_loss = F.mse_loss(output, target)\n",
    "\n",
    "        aux_loss = switch_load_balancing_loss(router_logits, config.expert_number)\n",
    "        # Combined loss\n",
    "        total_loss = mse_loss + 0.01 * aux_loss\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            print(f\"Batch {batch}, Loss: {total_loss.item():.4f} \"\n",
    "                  f\"(MSE: {mse_loss.item():.4f}, Aux: {aux_loss.item():.4f})\")\n",
    "\n",
    "# Run the training test\n",
    "test_moe_training()"
   ],
   "id": "34a182452b0d8058",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Loss: 2.3664 (MSE: 2.3461, Aux: 2.0238)\n",
      "Batch 10, Loss: 2.0350 (MSE: 2.0147, Aux: 2.0313)\n",
      "Batch 20, Loss: 1.8910 (MSE: 1.8707, Aux: 2.0292)\n",
      "Batch 30, Loss: 1.6639 (MSE: 1.6436, Aux: 2.0329)\n",
      "Batch 40, Loss: 1.4933 (MSE: 1.4728, Aux: 2.0466)\n",
      "Batch 50, Loss: 1.4352 (MSE: 1.4148, Aux: 2.0453)\n",
      "Batch 60, Loss: 1.3297 (MSE: 1.3091, Aux: 2.0618)\n",
      "Batch 70, Loss: 1.2803 (MSE: 1.2596, Aux: 2.0741)\n",
      "Batch 80, Loss: 1.2275 (MSE: 1.2067, Aux: 2.0810)\n",
      "Batch 90, Loss: 1.2094 (MSE: 1.1883, Aux: 2.1043)\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:07:24.908242Z",
     "start_time": "2025-05-16T10:07:24.896246Z"
    }
   },
   "cell_type": "code",
   "source": "router_logits = tensor = torch.empty(2 * 3 , 3).uniform_(0.0, 10.0) # (b * s, expert_number)",
   "id": "96d07cbacae37cde",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:07:25.394886Z",
     "start_time": "2025-05-16T10:07:25.374886Z"
    }
   },
   "cell_type": "code",
   "source": "router_logits # (b * s, expert_number)",
   "id": "460ff3925dddd1a6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9214, 4.9050, 8.1670],\n",
       "        [5.8767, 9.7485, 8.7586],\n",
       "        [8.9079, 6.8320, 8.6373],\n",
       "        [4.1807, 3.6645, 0.3205],\n",
       "        [0.4258, 5.4426, 3.3150],\n",
       "        [7.6354, 7.5148, 5.6424]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:07:28.644117Z",
     "start_time": "2025-05-16T10:07:28.621112Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # 计算路由概率\n",
    "router_probs = torch.softmax(router_logits, dim=-1)  # [b*s, num_experts] => (6,3)"
   ],
   "id": "b02b5296678bbaf3",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:07:34.865438Z",
     "start_time": "2025-05-16T10:07:34.837438Z"
    }
   },
   "cell_type": "code",
   "source": "router_probs # [b*s, num_experts] => (6,3)",
   "id": "fc50bad9118cfa59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.8650e-04, 3.6872e-02, 9.6244e-01],\n",
       "        [1.4954e-02, 7.1816e-01, 2.6688e-01],\n",
       "        [5.2956e-01, 6.6430e-02, 4.0401e-01],\n",
       "        [6.1809e-01, 3.6889e-01, 1.3020e-02],\n",
       "        [5.8860e-03, 8.8829e-01, 1.0582e-01],\n",
       "        [4.9441e-01, 4.3822e-01, 6.7377e-02]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:17:26.638859Z",
     "start_time": "2025-05-16T10:17:26.626506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取每个token的最优专家\n",
    "selected_experts_weight, selected_experts = torch.topk(router_probs, k=2, dim=-1)  # [b*s, top_k] => (6,2)\n"
   ],
   "id": "289b029901dc43b2",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:29:16.993777Z",
     "start_time": "2025-05-16T10:29:16.967976Z"
    }
   },
   "cell_type": "code",
   "source": "selected_experts_weight",
   "id": "25b49b910808a176",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9624, 0.0369],\n",
       "        [0.7182, 0.2669],\n",
       "        [0.5296, 0.4040],\n",
       "        [0.6181, 0.3689],\n",
       "        [0.8883, 0.1058],\n",
       "        [0.4944, 0.4382]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:28:59.118656Z",
     "start_time": "2025-05-16T10:28:59.093524Z"
    }
   },
   "cell_type": "code",
   "source": "selected_experts",
   "id": "3ccd5418fc915152",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1],\n",
       "        [1, 2],\n",
       "        [0, 2],\n",
       "        [0, 1],\n",
       "        [1, 2],\n",
       "        [0, 1]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:17:28.194042Z",
     "start_time": "2025-05-16T10:17:28.181600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建one-hot矩阵表示选中的专家\n",
    "mask = torch.nn.functional.one_hot(selected_experts, 3).float()  # [b*s, top_k, num_experts] => (6,2,3)"
   ],
   "id": "614681228b652da8",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:31:33.522613Z",
     "start_time": "2025-05-16T10:31:33.506293Z"
    }
   },
   "cell_type": "code",
   "source": "mask[:,:,0]",
   "id": "a76a7ecd795fc3cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:17:34.078830Z",
     "start_time": "2025-05-16T10:17:34.068550Z"
    }
   },
   "cell_type": "code",
   "source": "mask.shape",
   "id": "a437aadd1bd676af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2, 3])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:19:32.490222Z",
     "start_time": "2025-05-16T10:19:32.477972Z"
    }
   },
   "cell_type": "code",
   "source": "expert_mask = mask.permute(2, 1, 0)  # (expert_number, top_k, b * s) => (3, 2, 6)",
   "id": "3d77d026233b28c3",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:26:26.723393Z",
     "start_time": "2025-05-16T10:26:26.715396Z"
    }
   },
   "cell_type": "code",
   "source": "expert_mask[0].shape # (2, 6)",
   "id": "b89e2aab74268e2f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:26:43.773914Z",
     "start_time": "2025-05-16T10:26:43.761526Z"
    }
   },
   "cell_type": "code",
   "source": "expert_mask[0]",
   "id": "35278b07c096650e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:26:27.301454Z",
     "start_time": "2025-05-16T10:26:27.288456Z"
    }
   },
   "cell_type": "code",
   "source": "idx, top_x = torch.where(expert_mask[0])",
   "id": "f89b28ece8ce9dd4",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:26:30.317280Z",
     "start_time": "2025-05-16T10:26:30.304901Z"
    }
   },
   "cell_type": "code",
   "source": "idx",
   "id": "d9d04c41824009aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:26:51.240995Z",
     "start_time": "2025-05-16T10:26:51.221321Z"
    }
   },
   "cell_type": "code",
   "source": "top_x",
   "id": "3277d3736d0fe4c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 5])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:28:44.148698Z",
     "start_time": "2025-05-16T10:28:44.127722Z"
    }
   },
   "cell_type": "code",
   "source": "selected_experts_weight",
   "id": "96931c3b861776a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9624, 0.0369],\n",
       "        [0.7182, 0.2669],\n",
       "        [0.5296, 0.4040],\n",
       "        [0.6181, 0.3689],\n",
       "        [0.8883, 0.1058],\n",
       "        [0.4944, 0.4382]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:33:01.388986Z",
     "start_time": "2025-05-16T10:33:01.337619Z"
    }
   },
   "cell_type": "code",
   "source": "selected_experts_weight[idx, top_x].unsqueeze(-1)",
   "id": "cec6587fe60d90b2",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[99], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mselected_experts_weight\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_x\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mIndexError\u001B[0m: index 2 is out of bounds for dimension 1 with size 2"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4e91038071a35fb1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
